
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mindspore-lab.github.io/mindocr/inference/inference_thirdparty_quickstart/">
      
      
        <link rel="prev" href="../inference_quickstart/">
      
      
        <link rel="next" href="../convert_tutorial/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>Inference - Third-party Models - MindOCR Docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#third-party-models-offline-inference-quick-start" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="MindOCR Docs" class="md-header__button md-logo" aria-label="MindOCR Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindOCR Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Inference - Third-party Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.52 17.52 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04M18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12m-2.62 7 1.62-4.33L19.12 17h-3.24Z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="./" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="../../zh/inference/inference_thirdparty_quickstart/" hreflang="zh" class="md-select__link">
              中文
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindocr" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindocr
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../mkdocs/modelzoo_training/" class="md-tabs__link">
          
  
    
  
  Model Zoo

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../datasets/converters/" class="md-tabs__link">
          
  
    
  
  Tutorials

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../mkdocs/contributing/" class="md-tabs__link">
          
  
    
  
  Notes

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="MindOCR Docs" class="md-nav__button md-logo" aria-label="MindOCR Docs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    MindOCR Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindocr" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindocr
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Model Zoo
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Model Zoo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/modelzoo_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Training
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference_quickstart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference - MindOCR Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Inference - Third-party Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Inference - Third-party Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#third-party-models-offline-inference-quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      Third-party Models Offline Inference - Quick Start
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Third-party Models Offline Inference - Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-third-party-model-support-list" class="md-nav__link">
    <span class="md-ellipsis">
      1. Third-Party Model Support List
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Third-Party Model Support List">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Text recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-text-angle-classification" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Text angle classification
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-overview-of-third-party-inference" class="md-nav__link">
    <span class="md-ellipsis">
      2. Overview of Third-Party Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-third-party-model-inference-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Third-Party Model Inference Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Third-Party Model Inference Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#311-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.4 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#315-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.5 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Text Recognition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 Text Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-download-the-dictionary-file-for-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.4 Download the Dictionary File for Recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#325-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.5 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#326-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.6 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-text-direction-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Text Direction Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Text Direction Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#331-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#332-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-end-to-end-inference" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 End to End Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-quick-convertion-tool" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 Quick Convertion Tool
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4faq-about-converting-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      4.FAQ about converting and inference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    1. Datasets
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            1. Datasets
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../datasets/converters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset Preparation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/transform_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data Transformation Mechanism
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    2. Model Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            2. Model Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/yaml_configuration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Yaml Configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/training_detection_custom_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text Detection
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/training_recognition_custom_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text Recognition
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/distribute_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Distributed Training
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/advanced_train/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Advance Training
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    3. Inference and Deployment
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            3. Inference and Deployment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/online_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python Online Inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Python/C++ Inference on Ascend 310
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference_quickstart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inference - MindOCR Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Inference - Third-party Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Inference - Third-party Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#third-party-models-offline-inference-quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      Third-party Models Offline Inference - Quick Start
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Third-party Models Offline Inference - Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-third-party-model-support-list" class="md-nav__link">
    <span class="md-ellipsis">
      1. Third-Party Model Support List
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Third-Party Model Support List">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Text recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-text-angle-classification" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Text angle classification
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-overview-of-third-party-inference" class="md-nav__link">
    <span class="md-ellipsis">
      2. Overview of Third-Party Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-third-party-model-inference-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Third-Party Model Inference Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Third-Party Model Inference Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#311-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.4 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#315-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.5 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Text Recognition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 Text Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-download-the-dictionary-file-for-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.4 Download the Dictionary File for Recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#325-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.5 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#326-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.6 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-text-direction-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Text Direction Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Text Direction Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#331-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#332-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-end-to-end-inference" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 End to End Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-quick-convertion-tool" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 Quick Convertion Tool
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4faq-about-converting-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      4.FAQ about converting and inference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../convert_tutorial/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Conversion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    4. Developer Guides
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            4. Developer Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/customize_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/customize_data_transform/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Data Transformation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/customize_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize a New Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/customize_postprocess/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Customize Postprocessing Method
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Notes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mkdocs/contributing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tutorials/frequently_asked_questions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#third-party-models-offline-inference-quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      Third-party Models Offline Inference - Quick Start
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Third-party Models Offline Inference - Quick Start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-third-party-model-support-list" class="md-nav__link">
    <span class="md-ellipsis">
      1. Third-Party Model Support List
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Third-Party Model Support List">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Text recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-text-angle-classification" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Text angle classification
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-overview-of-third-party-inference" class="md-nav__link">
    <span class="md-ellipsis">
      2. Overview of Third-Party Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-third-party-model-inference-methods" class="md-nav__link">
    <span class="md-ellipsis">
      3. Third-Party Model Inference Methods
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Third-Party Model Inference Methods">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-text-detection" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Text Detection
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#311-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#312-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#313-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#314-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.4 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#315-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.1.5 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-text-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Text Recognition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.2 Text Recognition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#321-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#322-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#323-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#324-download-the-dictionary-file-for-recognition" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.4 Download the Dictionary File for Recognition
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#325-inference-with-lite-mindir" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.5 Inference with Lite MindIR
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#326-evalution" class="md-nav__link">
    <span class="md-ellipsis">
      3.2.6 Evalution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-text-direction-classification" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Text Direction Classification
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3.3 Text Direction Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#331-download-thirdparty-model-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.1 Download Thirdparty model file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#332-convert-the-thirdparty-model-to-onnx-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.2 Convert the thirdparty model to onnx file
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#333-convert-onnx-file-to-lite-mindir-file" class="md-nav__link">
    <span class="md-ellipsis">
      3.3.3 Convert onnx file to Lite MindIR file
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-end-to-end-inference" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 End to End Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-quick-convertion-tool" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 Quick Convertion Tool
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4faq-about-converting-and-inference" class="md-nav__link">
    <span class="md-ellipsis">
      4.FAQ about converting and inference
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindocr/edit/master/docs/en/inference/inference_thirdparty_quickstart.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindocr/raw/master/docs/en/inference/inference_thirdparty_quickstart.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


  <h1>Inference - Third-party Models</h1>

<h2 id="third-party-models-offline-inference-quick-start">Third-party Models Offline Inference - Quick Start<a class="headerlink" href="#third-party-models-offline-inference-quick-start" title="Permanent link">&para;</a></h2>
<h3 id="1-third-party-model-support-list">1. Third-Party Model Support List<a class="headerlink" href="#1-third-party-model-support-list" title="Permanent link">&para;</a></h3>
<p>MindOCR supports the inference of third-party models (PaddleOCR, MMOCR, etc.), and this document displays a list of adapted models. The performance test is based on Ascend310P, and some models have no test data set yet.</p>
<h4 id="11-text-detection">1.1 Text Detection<a class="headerlink" href="#11-text-detection" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th style="text-align: center;">name</th>
<th style="text-align: center;">model</th>
<th style="text-align: center;">backbone</th>
<th style="text-align: center;">dataset</th>
<th style="text-align: center;">F-score(%)</th>
<th style="text-align: center;">FPS</th>
<th style="text-align: center;">source</th>
<th style="text-align: center;">config</th>
<th style="text-align: center;">download</th>
<th style="text-align: center;">reference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ch_pp_det_OCRv4</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_PP-OCRv4_det_cml.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_ch/PP-OCRv4_introduction.md">ch_PP-OCRv4_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_server_det_v2.0</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">ResNet18_vd</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">46.22</td>
<td style="text-align: center;">21.65</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_det_res18_db_v2.0.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_server_v2.0_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_det_OCRv3</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">33.89</td>
<td style="text-align: center;">22.40</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_PP-OCRv3_det_cml.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_PP-OCRv3_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_det_OCRv2</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">42.99</td>
<td style="text-align: center;">21.90</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_PP-OCRv2_det_cml.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_PP-OCRv2_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_mobile_det_v2.0_slim</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">31.66</td>
<td style="text-align: center;">19.88</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_det_mv3_db_v2.0.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/slim/ch_ppocr_mobile_v2.0_det_prune_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_mobile_slim_v2.0_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_mobile_det_v2.0</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">31.56</td>
<td style="text-align: center;">21.96</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_det_mv3_db_v2.0.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_mobile_v2.0_det</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_det_OCRv3</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">42.14</td>
<td style="text-align: center;">55.55</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_PP-OCRv3_det_cml.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">en_PP-OCRv3_det</a></td>
</tr>
<tr>
<td style="text-align: center;">ml_pp_det_OCRv3</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17</td>
<td style="text-align: center;">66.01</td>
<td style="text-align: center;">22.48</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/ch_PP-OCRv3_det_cml.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/Multilingual_PP-OCRv3_det_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ml_PP-OCRv3_det</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_det_dbnet_resnet50vd</td>
<td style="text-align: center;">DBNet</td>
<td style="text-align: center;">ResNet50_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">79.89</td>
<td style="text-align: center;">21.17</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/det_r50_vd_db.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_r50_vd_db_v2.0_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_det_db_en.md">DBNet</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_det_psenet_resnet50vd</td>
<td style="text-align: center;">PSE</td>
<td style="text-align: center;">ResNet50_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">80.44</td>
<td style="text-align: center;">7.75</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/det_r50_vd_pse.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/det_r50_vd_pse_v2.0_train.tar">train model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_det_psenet_en.md">PSE</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_det_east_resnet50vd</td>
<td style="text-align: center;">EAST</td>
<td style="text-align: center;">ResNet50_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">85.58</td>
<td style="text-align: center;">20.70</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/det_r50_vd_east.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_r50_vd_east_v2.0_infer.tar">train model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_det_east_en.md">EAST</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_det_sast_resnet50vd</td>
<td style="text-align: center;">SAST</td>
<td style="text-align: center;">ResNet50_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">81.77</td>
<td style="text-align: center;">22.14</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/ppocr/det_r50_vd_sast_icdar15.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_r50_vd_sast_icdar15_v2.0_train.tar">train model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_det_sast_en.md">SAST</a></td>
</tr>
<tr>
<td style="text-align: center;">en_mm_det_dbnetpp_resnet50</td>
<td style="text-align: center;">DBNet++</td>
<td style="text-align: center;">ResNet50</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">81.36</td>
<td style="text-align: center;">10.66</td>
<td style="text-align: center;">MMOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/mmocr/dbnetpp_resnet50_fpnc_1200e_icdar2015.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://download.openmmlab.com/mmocr/textdet/dbnetpp/dbnetpp_resnet50_fpnc_1200e_icdar2015/dbnetpp_resnet50_fpnc_1200e_icdar2015_20221025_185550-013730aa.pth">train model</a></td>
<td style="text-align: center;"><a href="https://github.com/open-mmlab/mmocr/blob/main/configs/textdet/dbnetpp/README.md">DBNetpp</a></td>
</tr>
<tr>
<td style="text-align: center;">en_mm_det_fcenet_resnet50</td>
<td style="text-align: center;">FCENet</td>
<td style="text-align: center;">ResNet50</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">83.67</td>
<td style="text-align: center;">3.34</td>
<td style="text-align: center;">MMOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/det/mmocr/fcenet_resnet50_fpn_1500e_icdar2015.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://download.openmmlab.com/mmocr/textdet/fcenet/fcenet_resnet50_fpn_1500e_icdar2015/fcenet_resnet50_fpn_1500e_icdar2015_20220826_140941-167d9042.pth">train model</a></td>
<td style="text-align: center;"><a href="https://github.com/open-mmlab/mmocr/blob/main/configs/textdet/fcenet/README.md">FCENet</a></td>
</tr>
</tbody>
</table>
<p><strong>Notice: When using the en_pp_det_psenet_resnet50vd model for inference, you need to modify the onnx file with the
following command</strong></p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/models_utils/onnx_optim/insert_pse_postprocess.py<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--model_path<span class="o">=</span>./pse_r50vd.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--binary_thresh<span class="o">=</span><span class="m">0</span>.0<span class="w"> </span><span class="se">\</span>
<span class="w">      </span>--scale<span class="o">=</span><span class="m">1</span>.0
</code></pre></div>
<h4 id="12-text-recognition">1.2 Text recognition<a class="headerlink" href="#12-text-recognition" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th style="text-align: center;">name</th>
<th style="text-align: center;">model</th>
<th style="text-align: center;">backbone</th>
<th style="text-align: center;">dataset</th>
<th style="text-align: center;">Acc(%)</th>
<th style="text-align: center;">FPS</th>
<th style="text-align: center;">source</th>
<th style="text-align: center;">dict file</th>
<th style="text-align: left;">config</th>
<th style="text-align: left;">download</th>
<th style="text-align: left;">reference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ch_pp_rec_OCRv4</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/ch_PP-OCRv4_rec_distillation.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/doc/doc_ch/PP-OCRv4_introduction.md">ch_PP-OCRv4_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_server_rec_v2.0</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">ResNet34</td>
<td style="text-align: center;">MLT17 (ch)</td>
<td style="text-align: center;">49.91</td>
<td style="text-align: center;">154.16</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_chinese_common_v2.0.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_server_v2.0_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">MLT17 (ch)</td>
<td style="text-align: center;">49.91</td>
<td style="text-align: center;">408.38</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/ch_PP-OCRv3_rec_distillation.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_rec_OCRv2</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">MLT17 (ch)</td>
<td style="text-align: center;">44.59</td>
<td style="text-align: center;">203.34</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/ch_PP-OCRv2_rec_distillation.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv2/chinese/ch_PP-OCRv2_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_PP-OCRv2_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ch_pp_mobile_rec_v2.0</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">MLT17 (ch)</td>
<td style="text-align: center;">24.59</td>
<td style="text-align: center;">167.67</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_chinese_lite_v2.0.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_mobile_v2.0_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">MLT17 (en)</td>
<td style="text-align: center;">79.79</td>
<td style="text-align: center;">917.01</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/en_dict.txt">en_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/en_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">en_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_mobile_rec_number_v2.0_slim</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/en_dict.txt">en_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_en_number_lite.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/en_number_mobile_v2.0_rec_slim_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">en_number_mobile_slim_v2.0_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_mobile_rec_number_v2.0</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/en_dict.txt">en_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_en_number_lite.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/multilingual/en_number_mobile_v2.0_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">en_number_mobile_v2.0_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">korean_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/korean_dict.txt">korean_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/korean_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/korean_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">korean_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">japan_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/japan_dict.txt">japan_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/japan_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/japan_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">japan_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">chinese_cht_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/chinese_cht_dict.txt">chinese_cht_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/chinese_cht_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/chinese_cht_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">chinese_cht_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">te_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/te_dict.txt">te_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/te_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/te_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">te_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ka_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/ka_dict.txt">ka_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/ka_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/ka_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ka_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">ta_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/ta_dict.txt">ta_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/ta_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/ta_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ta_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">latin_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/latin_dict.txt">latin_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/latin_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/latin_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">latin_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">arabic_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/arabic_dict.txt">arabic_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/arabic_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/arabic_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">arabic_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">cyrillic_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/cyrillic_dict.txt">cyrillic_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/cyrillic_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/cyrillic_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">cyrillic_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">devanagari_pp_rec_OCRv3</td>
<td style="text-align: center;">SVTR</td>
<td style="text-align: center;">MobileNetV1Enhance</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/dict/devanagari_dict.txt">devanagari_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/devanagari_PP-OCRv3_rec.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/devanagari_PP-OCRv3_rec_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">devanagari_PP-OCRv3_rec</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_rec_crnn_resnet34vd</td>
<td style="text-align: center;">CRNN</td>
<td style="text-align: center;">ResNet34_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">66.35</td>
<td style="text-align: center;">420.80</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ic15_dict.txt">ic15_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_r34_vd_none_bilstm_ctc.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_r34_vd_none_bilstm_ctc_v2.0_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6rc/doc/doc_en/algorithm_rec_crnn_en.md">CRNN</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_rec_rosetta_resnet34vd</td>
<td style="text-align: center;">Rosetta</td>
<td style="text-align: center;">Resnet34_vd</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">64.28</td>
<td style="text-align: center;">552.40</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ic15_dict.txt">ic15_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_r34_vd_none_none_ctc.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_r34_vd_none_none_ctc_v2.0_infer.tar">infer model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_rec_rosetta_en.md">Rosetta</a></td>
</tr>
<tr>
<td style="text-align: center;">en_pp_rec_vitstr_vitstr</td>
<td style="text-align: center;">ViTSTR</td>
<td style="text-align: center;">ViTSTR</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">68.42</td>
<td style="text-align: center;">364.67</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/EN_symbol_dict.txt">EN_symbol_dict.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/ppocr/rec_vitstr_none_ce.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://paddleocr.bj.bcebos.com/rec_vitstr_none_ce_train.tar">train model</a></td>
<td style="text-align: left;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/algorithm_rec_vitstr_en.md">ViTSTR</a></td>
</tr>
<tr>
<td style="text-align: center;">en_mm_rec_nrtr_resnet31</td>
<td style="text-align: center;">NRTR</td>
<td style="text-align: center;">ResNet31</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">67.26</td>
<td style="text-align: center;">32.63</td>
<td style="text-align: center;">MMOCR</td>
<td style="text-align: center;"><a href="https://github.com/open-mmlab/mmocr/blob/main/dicts/english_digits_symbols.txt">english_digits_symbols.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/mmocr/nrtr_resnet31-1by8-1by4_6e_st_mj.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://download.openmmlab.com/mmocr/textrecog/nrtr/nrtr_resnet31-1by8-1by4_6e_st_mj/nrtr_resnet31-1by8-1by4_6e_st_mj_20220916_103322-a6a2a123.pth">train model</a></td>
<td style="text-align: left;"><a href="https://github.com/open-mmlab/mmocr/blob/main/configs/textrecog/nrtr/README.md">NRTR</a></td>
</tr>
<tr>
<td style="text-align: center;">en_mm_rec_satrn_shallowcnn</td>
<td style="text-align: center;">SATRN</td>
<td style="text-align: center;">ShallowCNN</td>
<td style="text-align: center;">IC15</td>
<td style="text-align: center;">73.52</td>
<td style="text-align: center;">32.14</td>
<td style="text-align: center;">MMOCR</td>
<td style="text-align: center;"><a href="https://github.com/open-mmlab/mmocr/blob/main/dicts/english_digits_symbols.txt">english_digits_symbols.txt</a></td>
<td style="text-align: left;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/rec/mmocr/satrn_shallow_5e_st_mj.yaml">yaml</a></td>
<td style="text-align: left;"><a href="https://download.openmmlab.com/mmocr/textrecog/satrn/satrn_shallow_5e_st_mj/satrn_shallow_5e_st_mj_20220915_152443-5fd04a4c.pth">train model</a></td>
<td style="text-align: left;"><a href="https://github.com/open-mmlab/mmocr/blob/main/configs/textrecog/satrn/README.md">SATRN</a></td>
</tr>
</tbody>
</table>
<h4 id="13-text-angle-classification">1.3 Text angle classification<a class="headerlink" href="#13-text-angle-classification" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th style="text-align: center;">name</th>
<th style="text-align: center;">model</th>
<th style="text-align: center;">dataset</th>
<th style="text-align: center;">Acc(%)</th>
<th style="text-align: center;">FPS</th>
<th style="text-align: center;">source</th>
<th style="text-align: center;">config</th>
<th style="text-align: center;">download</th>
<th style="text-align: center;">reference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ch_pp_mobile_cls_v2.0</td>
<td style="text-align: center;">MobileNetV3</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">/</td>
<td style="text-align: center;">PaddleOCR</td>
<td style="text-align: center;"><a href="https://github.com/mindspore-lab/mindocr/tree/main/deploy/py_infer/src/configs/cls/ppocr/cls_mv3.yaml">yaml</a></td>
<td style="text-align: center;"><a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar">infer model</a></td>
<td style="text-align: center;"><a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/doc/doc_en/models_list_en.md">ch_ppocr_mobile_v2.0_cls</a></td>
</tr>
</tbody>
</table>
<h3 id="2-overview-of-third-party-inference">2. Overview of Third-Party Inference<a class="headerlink" href="#2-overview-of-third-party-inference" title="Permanent link">&para;</a></h3>
<pre class="mermaid"><code>graph LR;
    A[ThirdParty models] -- xx2onnx --&gt; B[ONNX] -- converter_lite --&gt; C[MindIR];
    C --input --&gt; D[infer.py] -- outputs --&gt; eval_rec.py/eval_det.py;
    H[images] --input --&gt; D[infer.py];</code></pre>
<h3 id="3-third-party-model-inference-methods">3. Third-Party Model Inference Methods<a class="headerlink" href="#3-third-party-model-inference-methods" title="Permanent link">&para;</a></h3>
<p>For ppocrv4, we provide <a href="#35-quick-convertion-tool">Quick Convertion Tool</a> for converting Paddle model to MindIR model.</p>
<h4 id="31-text-detection">3.1 Text Detection<a class="headerlink" href="#31-text-detection" title="Permanent link">&para;</a></h4>
<p>Let's take <code>ch_pp_det_OCRv4</code> in <a href="#11-text-detection">Third-Party Model Support List</a> as an example to introduce the inference method:</p>
<h4 id="311-download-thirdparty-model-file">3.1.1 Download Thirdparty model file<a class="headerlink" href="#311-download-thirdparty-model-file" title="Permanent link">&para;</a></h4>
<ul>
<li>In <a href="#11-text-detection">Third-Party Model Support List</a>, <code>infer model</code> indicates model file for inference; <code>train model</code> indicates model file for training, and it need to be converted to inference model first.</li>
<li>If the model file is <code>infer model</code>, like <code>ch_pp_det_OCRv4</code>, dowload and extract <a href="https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_det_infer.tar">infer model</a> and get the following folder:
     <code>text
    ch_PP-OCRv4_det_infer/
    ├── inference.pdmodel
    ├── inference.pdiparams
    ├── inference.pdiparams.info</code></li>
<li>If the model file is <code>train model</code>, like <code>en_pp_det_psenet_resnet50vd</code>, dowload and extract <a href="https://paddleocr.bj.bcebos.com/dygraph_v2.1/en_det/det_r50_vd_pse_v2.0_train.tar">train model</a> and get the following folder:
    <div class="highlight"><pre><span></span><code>det_r50_vd_pse_v2.0_train/
├── train.log
├── best_accuracy.pdopt
├── best_accuracy.states
├── best_accuracy.pdparams
</code></pre></div>
    And it need to be converted by the following commands:
    <div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/PaddlePaddle/PaddleOCR.git
<span class="nb">cd</span><span class="w"> </span>PaddleOCR
python<span class="w"> </span>tools/export_model.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-c<span class="w"> </span>configs/det/det_r50_vd_pse.yml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-o<span class="w"> </span>Global.pretrained_model<span class="o">=</span>./det_r50_vd_pse_v2.0_train/best_accuracy<span class="w">  </span><span class="se">\</span>
<span class="w">    </span>Global.save_inference_dir<span class="o">=</span>./det_db
</code></pre></div>
    and you will get the following folder:
    <div class="highlight"><pre><span></span><code>det_db/
├── inference.pdmodel
├── inference.pdiparams
├── inference.pdiparams.info
</code></pre></div></li>
</ul>
<h4 id="312-convert-the-thirdparty-model-to-onnx-file">3.1.2 Convert the thirdparty model to onnx file<a class="headerlink" href="#312-convert-the-thirdparty-model-to-onnx-file" title="Permanent link">&para;</a></h4>
<p>Download and use the paddle2onnx tool</p>
<p><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>paddle2onnx
</code></pre></div>
and convert the inference model into an onnx file:</p>
<p><div class="highlight"><pre><span></span><code>paddle2onnx<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--model_dir<span class="w"> </span>det_db<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--model_filename<span class="w"> </span>inference.pdmodel<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--params_filename<span class="w"> </span>inference.pdiparams<span class="se">\</span>
<span class="w">     </span>--save_file<span class="w"> </span>det_db.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--opset_version<span class="w"> </span><span class="m">11</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--input_shape_dict<span class="o">=</span><span class="s2">&quot;{&#39;x&#39;:[-1,3,-1,-1]}&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--enable_onnx_checker<span class="w"> </span>True
</code></pre></div>
A brief explanation of parameters for paddle2onnx is as follows:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>--model_dir</td>
<td>Configures the directory path containing the Paddle model.</td>
</tr>
<tr>
<td>--model_filename</td>
<td><strong>[Optional]</strong> Configures the file name storing the network structure located under <code>--model_dir</code>.</td>
</tr>
<tr>
<td>--params_filename</td>
<td><strong>[Optional]</strong> Configures the file name storing the model parameters located under <code>--model_dir</code>.</td>
</tr>
<tr>
<td>--save_file</td>
<td>Specifies the directory path for saving the converted model.</td>
</tr>
<tr>
<td>--opset_version</td>
<td><strong>[Optional]</strong> Configures the OpSet version for converting to ONNX. Multiple versions, such as 7~16, are currently supported, and the default is 9.</td>
</tr>
<tr>
<td>--input_shape_dict</td>
<td>Specifies the shape of the input tensor for generating a dynamic ONNX model. The format is "{'x': [N, C, H, W]}", where -1 represents dynamic shape.</td>
</tr>
<tr>
<td>--enable_onnx_checker</td>
<td><strong>[Optional]</strong> Configures whether to check the correctness of the exported ONNX model. It is recommended to enable this switch, and the default is False.</td>
</tr>
</tbody>
</table>
<p>The value of <code>--input_shape_dict</code> in the parameter can be viewed by opening the inference model through the <a href="https://github.com/lutzroeder/netron">Netron</a> tool.</p>
<blockquote>
<p>Learn more about <a href="https://github.com/PaddlePaddle/Paddle2ONNX/tree/develop">paddle2onnx</a></p>
</blockquote>
<p>The <code>det_db.onnx</code> file will be generated after the above command is executed;</p>
<h4 id="313-convert-onnx-file-to-lite-mindir-file">3.1.3 Convert onnx file to Lite MindIR file<a class="headerlink" href="#313-convert-onnx-file-to-lite-mindir-file" title="Permanent link">&para;</a></h4>
<p>Use <code>converter_lite</code> tool on Ascend310/310P to convert onnx files to mindir:</p>
<p>Create <code>config.txt</code> and specify the model input shape:</p>
<ul>
<li>If converting to static shape model, like static shape of <code>[1,3,736,1280]</code>, the config is as following
     <div class="highlight"><pre><span></span><code>[ascend_context]
input_format=NCHW
input_shape=x:[1,3,736,1280]
</code></pre></div></li>
<li>If converting to dynamic shape(scaling) model, the config is as following
     <div class="highlight"><pre><span></span><code>[ascend_context]
input_format=NCHW
input_shape=x:[1,3,-1,-1]
dynamic_dims=[736,1280],[768,1280],[896,1280],[1024,1280]
</code></pre></div></li>
<li>If converting to dynamic shape model, the config is as following
     <div class="highlight"><pre><span></span><code>[acl_build_options]
input_format=NCHW
input_shape_range=x:[-1,3,-1,-1]
</code></pre></div></li>
</ul>
<p>A brief explanation of the configuration file parameters is as follows:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Attribute</th>
<th style="text-align: center;">Function Description</th>
<th style="text-align: center;">Data Type</th>
<th style="text-align: center;">Value Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">input_format</td>
<td style="text-align: center;">Optional</td>
<td style="text-align: center;">Specify the format of the model input</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">Optional values are "NCHW", "NHWC", "ND"</td>
</tr>
<tr>
<td style="text-align: center;">input_shape</td>
<td style="text-align: center;">Optional</td>
<td style="text-align: center;">Specify the shape of the model input. The input_name must be the input name in the original model, arranged in order of input, separated by ";"</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">For example: "input1:[1,64,64,3];input2:[1,256,256,3]"</td>
</tr>
<tr>
<td style="text-align: center;">dynamic_dims</td>
<td style="text-align: center;">Optional</td>
<td style="text-align: center;">Specify dynamic BatchSize and dynamic resolution parameters</td>
<td style="text-align: center;">String</td>
<td style="text-align: center;">For example: "dynamic_dims=[48,520],[48,320],[48,384]"</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Learn more about <a href="https://www.mindspore.cn/lite/docs/en/master/use/cloud_infer/converter_tool_ascend.html">Configuration File Parameters</a></p>
</blockquote>
<p>Run the following command:
<div class="highlight"><pre><span></span><code>converter_lite<span class="se">\</span>
<span class="w">     </span>--saveType<span class="o">=</span>MINDIR<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--optimize<span class="o">=</span>ascend_oriented<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--modelFile<span class="o">=</span>det_db.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--outputFile<span class="o">=</span>det_db_lite<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>--configFile<span class="o">=</span>config.txt
</code></pre></div>
After the above command is executed, the <code>det_db_lite.mindir</code> file will be generated;</p>
<p>A brief explanation of the <code>converter_lite</code> parameters is as follows:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">Required</th>
<th style="text-align: center;">Parameter Description</th>
<th style="text-align: center;">Value Range</th>
<th style="text-align: center;">Default</th>
<th style="text-align: center;">Remarks</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">fmk</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Input model format</td>
<td style="text-align: center;">MINDIR, CAFFE, TFLITE, TF, ONNX</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">saveType</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Set the exported model to MINDIR or MS model format.</td>
<td style="text-align: center;">MINDIR, MINDIR_LITE</td>
<td style="text-align: center;">MINDIR</td>
<td style="text-align: center;">The cloud-side inference version can only infer models converted to MINDIR format</td>
</tr>
<tr>
<td style="text-align: center;">modelFile</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Input model path</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">outputFile</td>
<td style="text-align: center;">Yes</td>
<td style="text-align: center;">Output model path. Do not add a suffix, ".mindir" suffix will be generated automatically.</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">configFile</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">1) Path to the quantization configuration file after training; 2) Path to the configuration file for extended functions</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">optimize</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">Set the model optimization type for the device. Default is none.</td>
<td style="text-align: center;">none、general、gpu_oriented、ascend_oriented</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Learn more about <a href="https://www.mindspore.cn/lite/docs/en/master/use/cloud_infer/converter_tool.html">converter_lite</a></p>
<p>Learn more about <a href="../convert_tutorial/">Model Conversion Tutorial</a></p>
</blockquote>
<h4 id="314-inference-with-lite-mindir">3.1.4 Inference with Lite MindIR<a class="headerlink" href="#314-inference-with-lite-mindir" title="Permanent link">&para;</a></h4>
<p>Perform inference using <code>deploy/py_infer/infer.py</code> codes and <code>det_db_lite.mindir</code> model file:</p>
<p><div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/py_infer/infer.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input_images_dir<span class="o">=</span>/path/to/ic15/ch4_test_images<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--det_model_path<span class="o">=</span>/path/to/mindir/det_db_lite.mindir<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--det_model_name_or_config<span class="o">=</span>ch_pp_det_OCRv4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--res_save_dir<span class="o">=</span>/path/to/ch_pp_det_OCRv4_results
</code></pre></div>
After the execution is completed, the prediction file <code>det_results.txt</code> will be generated in the directory pointed to by the parameter <code>--res_save_dir</code>.</p>
<p>When doing inference, you can use the <code>--vis_det_save_dir</code> parameter to visualize the results</p>
<blockquote>
<p>Learn more about <a href="../inference_tutorial/#42-detail-of-inference-parameter">infer.py</a> inference parameters</p>
</blockquote>
<h4 id="315-evalution">3.1.5 Evalution<a class="headerlink" href="#315-evalution" title="Permanent link">&para;</a></h4>
<p>Evaluate the results using the following command:</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/eval_utils/eval_det.py<span class="se">\</span>
<span class="w">    </span>--gt_path<span class="o">=</span>/path/to/ic15/test_det_gt.txt<span class="se">\</span>
<span class="w">    </span>--pred_path<span class="o">=</span>/path/to/ch_pp_det_OCRv4_results/det_results.txt
</code></pre></div>
<h3 id="32-text-recognition">3.2 Text Recognition<a class="headerlink" href="#32-text-recognition" title="Permanent link">&para;</a></h3>
<p>Let's take <code>ch_pp_rec_OCRv4</code> in <a href="#12-text-recognition">Third-Party Model Support List</a> as an example to introduce the inference method:</p>
<h4 id="321-download-thirdparty-model-file">3.2.1 Download Thirdparty model file<a class="headerlink" href="#321-download-thirdparty-model-file" title="Permanent link">&para;</a></h4>
<ul>
<li>In <a href="#12-text-recognition">Third-Party Model Support List</a>, <code>infer model</code> indicates model file for inference; <code>train model</code> indicates model file for training, and it need to be converted to inference model first.</li>
<li>
<p>If the model file is <code>infer model</code>, like <code>ch_pp_rec_OCRv4</code>, dowload and extract <a href="https://paddleocr.bj.bcebos.com/PP-OCRv4/chinese/ch_PP-OCRv4_rec_infer.tar">infer model</a> and get the following folder:</p>
<div class="highlight"><pre><span></span><code>ch_PP-OCRv4_det_infer/
├── inference.pdmodel
├── inference.pdiparams
├── inference.pdiparams.info
</code></pre></div>
</li>
<li>
<p>If the model file is <code>train model</code>, like <code>en_pp_rec_vitstr_vitstr</code>, dowload and extract <a href="https://paddleocr.bj.bcebos.com/rec_vitstr_none_ce_train.tar">train model</a> and get the following folder:</p>
<p><div class="highlight"><pre><span></span><code>rec_vitstr_none_ce_train/
├── train.log
├── best_accuracy.pdopt
├── best_accuracy.states
├── best_accuracy.pdparams
</code></pre></div>
And it need to be converted by the following commands:</p>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/PaddlePaddle/PaddleOCR.git
<span class="nb">cd</span><span class="w"> </span>PaddleOCR
python<span class="w"> </span>tools/export_model.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-c<span class="w"> </span>configs/rec/rec_vitstr_none_ce.yml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-o<span class="w"> </span>Global.pretrained_model<span class="o">=</span>./rec_vitstr_none_ce_train/best_accuracy<span class="w">  </span><span class="se">\</span>
<span class="w">    </span>Global.save_inference_dir<span class="o">=</span>./rec_vitstr
</code></pre></div>
<p>and you will get the following folder:</p>
<div class="highlight"><pre><span></span><code>rec_vitstr/
├── inference.pdmodel
├── inference.pdiparams
├── inference.pdiparams.info
</code></pre></div>
</li>
</ul>
<h4 id="322-convert-the-thirdparty-model-to-onnx-file">3.2.2 Convert the thirdparty model to onnx file<a class="headerlink" href="#322-convert-the-thirdparty-model-to-onnx-file" title="Permanent link">&para;</a></h4>
<p>Download and use the paddle2onnx tool</p>
<p><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>paddle2onnx
</code></pre></div>
and convert the inference model into an onnx file:</p>
<div class="highlight"><pre><span></span><code>paddle2onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_dir<span class="w"> </span>ch_PP-OCRv4_rec_infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_filename<span class="w"> </span>inference.pdmodel<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--params_filename<span class="w"> </span>inference.pdiparams<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_file<span class="w"> </span>rec_crnn.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--opset_version<span class="w"> </span><span class="m">11</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input_shape_dict<span class="o">=</span><span class="s2">&quot;{&#39;x&#39;:[-1,3,48,-1]}&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable_onnx_checker<span class="w"> </span>True
</code></pre></div>
<p>The <code>rec_crnn.onnx</code> file will be generated after the above command is executed;</p>
<p>Please refer to <a href="#312-convert-the-thirdparty-model-to-onnx-file">3.1.2 Convert the thirdparty model to onnx file</a> for details about <code>paddle2onnx</code>.</p>
<h4 id="323-convert-onnx-file-to-lite-mindir-file">3.2.3 Convert onnx file to Lite MindIR file<a class="headerlink" href="#323-convert-onnx-file-to-lite-mindir-file" title="Permanent link">&para;</a></h4>
<p>Use <code>converter_lite</code> tool on Ascend310/310P to convert onnx files to mindir:</p>
<p>Create <code>config.txt</code> and specify the model input shape:</p>
<ul>
<li>If converting to static shape model, like static shape of <code>[1,3,48,320]</code>, the config is as following
    <div class="highlight"><pre><span></span><code>[ascend_context]
input_format=NCHW
input_shape=x:[1,3,48,320]
</code></pre></div></li>
<li>If converting to dynamic shape(scaling) model, the config is as following
    <div class="highlight"><pre><span></span><code>[ascend_context]
input_format=NCHW
input_shape=x:[1,3,-1,-1]
dynamic_dims=[48,520],[48,320],[48,384],[48,360],[48,394],[48,321],[48,336],[48,368],[48,328],[48,685],[48,347]
</code></pre></div></li>
<li>If converting to dynamic shape model, the config is as following
    <div class="highlight"><pre><span></span><code>[acl_build_options]
input_format=NCHW
input_shape_range=x:[-1,3,-1,-1]
</code></pre></div></li>
</ul>
<p>For a brief description of the configuration parameters, please refer to <a href="#313-convert-onnx-file-to-lite-mindir-file">3.1.3 Convert onnx file to Lite MindIR file</a></p>
<p>Run the following command:
<div class="highlight"><pre><span></span><code>converter_lite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--saveType<span class="o">=</span>MINDIR<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--optimize<span class="o">=</span>ascend_oriented<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--modelFile<span class="o">=</span>rec_crnn.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--outputFile<span class="o">=</span>rec_crnn_lite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--configFile<span class="o">=</span>config.txt
</code></pre></div></p>
<p>After the above command is executed, the <code>rec_crnn_lite.mindir.mindir</code> file will be generated;</p>
<p>For a brief description of the <code>converter_lite</code> parameters, see the text detection example above.</p>
<blockquote>
<p>Learn more about <a href="https://www.mindspore.cn/lite/docs/en/master/use/cloud_infer/converter_tool.html">converter_lite</a></p>
<p>Learn more about <a href="../convert_tutorial/">Model Conversion Tutorial</a></p>
</blockquote>
<h4 id="324-download-the-dictionary-file-for-recognition">3.2.4 Download the Dictionary File for Recognition<a class="headerlink" href="#324-download-the-dictionary-file-for-recognition" title="Permanent link">&para;</a></h4>
<p>According to <a href="#12-text-recognition">Third-Party Model Support List</a>, download <a href="https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.6/ppocr/utils/ppocr_keys_v1.txt">ppocr_keys_v1.txt</a> which matches with <code>ch_pp_rec_OCRv4</code>.</p>
<h4 id="325-inference-with-lite-mindir">3.2.5 Inference with Lite MindIR<a class="headerlink" href="#325-inference-with-lite-mindir" title="Permanent link">&para;</a></h4>
<p>Perform inference using <code>deploy/py_infer/infer.py</code> codes and <code>rec_crnn_lite.mindir</code> model file:</p>
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/py_infer/infer.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input_images_dir<span class="o">=</span>/path/to/mlt17_ch<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rec_model_path<span class="o">=</span>/path/to/mindir/rec_crnn_lite.mindir<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rec_model_name_or_config<span class="o">=</span>ch_pp_rec_OCRv4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--character_dict_path<span class="o">=</span>/path/to/ppocr_keys_v1.txt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--res_save_dir<span class="o">=</span>/path/to/ch_rec_infer_results
</code></pre></div>
<p>After the execution is completed, the prediction file <code>rec_results.txt</code> will be generated in the directory pointed to by the parameter <code>--res_save_dir</code>.</p>
<blockquote>
<p>Learn more about <a href="../inference_tutorial/#42-detail-of-inference-parameter">infer.py</a> inference parameters</p>
</blockquote>
<h4 id="326-evalution">3.2.6 Evalution<a class="headerlink" href="#326-evalution" title="Permanent link">&para;</a></h4>
<p>Evaluate the results using the following command:</p>
<p><div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/eval_utils/eval_rec.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gt_path<span class="o">=</span>/path/to/mlt17_ch/chinese_gt.txt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pred_path<span class="o">=</span>/path/to/en_rec_infer_results/rec_results.txt
</code></pre></div>
Refer <a href="/docs/en/datasets/converters.md">Dataset converters</a> for dataset preparation.</p>
<h3 id="33-text-direction-classification">3.3 Text Direction Classification<a class="headerlink" href="#33-text-direction-classification" title="Permanent link">&para;</a></h3>
<p>Let's take <code>ch_pp_mobile_cls_v2</code> in <a href="#13-text-angle-classification">Third-Party Model Support List</a> as an example to introduce the inference method:</p>
<h4 id="331-download-thirdparty-model-file">3.3.1 Download Thirdparty model file<a class="headerlink" href="#331-download-thirdparty-model-file" title="Permanent link">&para;</a></h4>
<p>In <a href="#13-text-angle-classification">Third-Party Model Support List</a>
，<code>ch_pp_mobile_cls_v2.0</code> is a <a href="https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar">infer model</a>，so convertion is not needed. dowload and extract it and get the following folder:</p>
<div class="highlight"><pre><span></span><code>ch_ppocr_mobile_v2.0_cls_infer/
├── inference.pdmodel
├── inference.pdiparams
├── inference.pdiparams.info
</code></pre></div>
<h4 id="332-convert-the-thirdparty-model-to-onnx-file">3.3.2 Convert the thirdparty model to onnx file<a class="headerlink" href="#332-convert-the-thirdparty-model-to-onnx-file" title="Permanent link">&para;</a></h4>
<p>convert the inference model into an onnx file:</p>
<div class="highlight"><pre><span></span><code>paddle2onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_dir<span class="w"> </span>cls_mv3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_filename<span class="w"> </span>inference.pdmodel<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--params_filename<span class="w"> </span>inference.pdiparams<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_file<span class="w"> </span>cls_mv3.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--opset_version<span class="w"> </span><span class="m">11</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input_shape_dict<span class="o">=</span><span class="s2">&quot;{&#39;x&#39;:[-1,3,-1,-1]}&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--enable_onnx_checker<span class="w"> </span>True
</code></pre></div>
<p>The <code>cls_mv3.onnx</code> file will be generated after the above command is executed;</p>
<p>Please refer to <a href="#312-convert-the-thirdparty-model-to-onnx-file">3.1.2 Convert the thirdparty model to onnx file</a> for details about <code>paddle2onnx</code>.</p>
<h4 id="333-convert-onnx-file-to-lite-mindir-file">3.3.3 Convert onnx file to Lite MindIR file<a class="headerlink" href="#333-convert-onnx-file-to-lite-mindir-file" title="Permanent link">&para;</a></h4>
<p>Refer to <a href="#313-convert-onnx-file-to-lite-mindir-file">3.1.3 Convert onnx file to Lite MindIR file</a> and create <code>config.txt</code>, here we take dynamic shape config as example
<div class="highlight"><pre><span></span><code>[acl_build_options]
input_format=NCHW
input_shape_range=x:[-1,3,-1,-1]
</code></pre></div>
And run the following command:</p>
<div class="highlight"><pre><span></span><code>converter_lite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--saveType<span class="o">=</span>MINDIR<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--fmk<span class="o">=</span>ONNX<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--optimize<span class="o">=</span>ascend_oriented<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--modelFile<span class="o">=</span>cls_mv3.onnx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--outputFile<span class="o">=</span>cls_mv3_lite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--configFile<span class="o">=</span>config.txt
</code></pre></div>
<p>After the above command is executed, the <code>cls_mv3_lite.mindir.mindir</code> file will be generated</p>
<h3 id="34-end-to-end-inference">3.4 End to End Inference<a class="headerlink" href="#34-end-to-end-inference" title="Permanent link">&para;</a></h3>
<p>Prepare mindIR according to <a href="#31-text-detection">Text Detection</a>, <a href="#32-text-recognition">Text Recognition</a>, <a href="#33-text-direction-classification">Text Direction Classification</a>, and run the following command to do end-to-end inference
<div class="highlight"><pre><span></span><code>python<span class="w"> </span>deploy/py_infer/infer.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--input_images_dir<span class="o">=</span>/path/to/ic15/ch4_test_images<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--det_model_path<span class="o">=</span>/path/to/mindir/det_db_lite.mindir<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--det_model_name_or_config<span class="o">=</span>ch_pp_det_OCRv4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cls_model_path<span class="o">=</span>/path/to/mindir/cls_mv3_lite.mindir<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cls_model_name_or_config<span class="o">=</span>ch_pp_mobile_cls_v2.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rec_model_path<span class="o">=</span>/path/to/mindir/rec_crnn_lite.mindir<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rec_model_name_or_config<span class="o">=</span>ch_pp_rec_OCRv4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--character_dict_path<span class="o">=</span>/path/to/ppocr_keys_v1.txt<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--res_save_dir<span class="o">=</span>/path/to/infer_results
</code></pre></div></p>
<h3 id="35-quick-convertion-tool">3.5 Quick Convertion Tool<a class="headerlink" href="#35-quick-convertion-tool" title="Permanent link">&para;</a></h3>
<p>For ppocrv4，we provide tools for converting Paddle model to MindIR model, the guidence is as following:
 - Make sure <code>MindSpore Lite</code> has been downloaded and configured successfully, please refer to <a href="https://www.mindspore.cn/lite">MindSpore Lite</a>. And make sure <code>converter_lite</code> has been added into the environment variable.
 - Run the following command:
<div class="highlight"><pre><span></span><code><span class="nb">cd</span><span class="w"> </span>tools
bash<span class="w"> </span>paddle2mindir.sh<span class="w"> </span>-m<span class="o">=</span><span class="si">${</span><span class="nv">ppocr_model_name</span><span class="si">}</span><span class="w"> </span>-p<span class="o">=</span><span class="si">${</span><span class="nv">save_dir</span><span class="si">}</span>
</code></pre></div>
 - <code>$ppocr_model_name</code>: ppocr models to be converted. <code>ch_PP-OCRv4</code>, <code>ch_PP-OCRv4_server</code> are supported
 - <code>$save_dir</code>: folder to save downloaded ppocr models and converted mindir. Default: ppocr_models</p>
<p>The convertion may cost minutes, please wait. And You could get the following MindIR models after convertion:
<div class="highlight"><pre><span></span><code>ppocr_models
├── ${PPOCR_MODEL_NAME}_det_db_dynamic_output.mindir
├── ${PPOCR_MODEL_NAME}_rec_crnn_static_output.mindir
├── ${PPOCR_MODEL_NAME}_cls_mv4_static_output.mindir
├── ...
</code></pre></div></p>
<h2 id="4faq-about-converting-and-inference">4.FAQ about converting and inference<a class="headerlink" href="#4faq-about-converting-and-inference" title="Permanent link">&para;</a></h2>
<p>For problems about converting model and inference, please refer to <a href="../../tutorials/frequently_asked_questions/">FAQ</a> for solutions.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../inference_quickstart/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Inference - MindOCR Models">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Inference - MindOCR Models
              </div>
            </div>
          </a>
        
        
          
          <a href="../convert_tutorial/" class="md-footer__link md-footer__link--next" aria-label="Next: Model Conversion">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Model Conversion
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2024 MindSpore Lab
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:mindspore-lab@huawei.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindocr" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/mindsporelab" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13H170.54zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82v170.31zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62v.01zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2l19.23 14.43zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78l.03-.01z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.indexes", "navigation.top", "navigation.footer", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>